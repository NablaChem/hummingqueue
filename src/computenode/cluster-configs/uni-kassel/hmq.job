#!/bin/bash
#SBATCH --partition=${partitions}
#SBATCH --nodes=1
#SBATCH --mem-per-cpu=4000
#SBATCH --time-min=6:00:00
#SBATCH --time=24:00:00
#SBATCH --job-name="hmqnode"
#SBATCH --output=/dev/null
#SBATCH --error=/dev/null
#SBATCH --exclusive
#SBATCH --signal=B:15@120

# libraries called from python modules themselves may look for several environment variables
export OMP_NUM_THREADS=${ncores}
export MKL_NUM_THREADS=${ncores}
export NUMEXPR_NUM_THREADS=${ncores}
export OPENBLAS_NUM_THREADS=${ncores}
export VECLIB_MAXIMUM_THREADS=${ncores}

# load env once
export MAMBA_ROOT_PREFIX="${envs}"
eval "$$(${binaries}/micromamba shell hook --shell bash )"
micromamba activate hmq_${pyver}

# cleanup support
cleanup() {
	# kill all descendant jobs
	pkill -P $$
	
	# delete tmp directories
	rm -rf /local/workdir-$$SLURM_JOB_ID-*
}
trap cleanup 15

# run in local tmpdir
for INSTANCE in $$( seq $$(( $$SLURM_JOB_CPUS_PER_NODE/${ncores} )) );
do
	TMPDIR="/local/workdir-$$SLURM_JOB_ID-$$INSTANCE"
	mkdir $$TMPDIR
	cd $$TMPDIR
	export PYSCF_TMPDIR=$$TMPDIR
	cat << EOF > config.py
REDIS_HOST = '${redis_host}'
REDIS_PORT = '${redis_port}'
REDIS_PASSWORD = '${redis_pass}'
EOF
	rq worker -c config -w hmq.CachedWorker --max-idle-time 60 --quiet --burst ${queues} > /dev/null 2>&1 &
	cd 
done

# wait for all subprocesses to be complete
wait
cleanup
