#!/bin/bash
#SBATCH --partition=public
#SBATCH --nodes=1
#SBATCH --mem-per-cpu=4000
#SBATCH --time-min=0:30:00
#SBATCH --time=24:00:00
#SBATCH --job-name="hmqnode"
#SBATCH --output=/dev/null
#SBATCH --error=/dev/null
#SBATCH --exclusive
#SBATCH --signal=B:15@120

# libraries called from python modules themselves may look for several environment variables
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
export NUMEXPR_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1

# load env once
export MAMBA_ROOT_PREFIX="/home/users/0026/uk092940/hmq/envs"
eval "$(./micromamba shell hook --shell bash )"
micromamba activate hmq_3.9

# cleanup support
cleanup() {
	# kill all descendant jobs
	pkill -P $$
	
	# delete tmp directories
	rm -rf /local/workdir-$SLURM_JOB_ID-*
	
}
trap cleanup 15

# run in local tmpdir
for INSTANCE in $(seq $SLURM_JOB_CPUS_PER_NODE);
do
	TMPDIR="/local/workdir-$SLURM_JOB_ID-$INSTANCE"
	mkdir $TMPDIR
	cp -r $SLURM_SUBMIT_DIR/local/* $TMPDIR/
	cd $TMPDIR
	export PYSCF_TMPDIR=$TMPDIR
	make worker > /dev/null 2>&1 &
	cd 
done

# wait for all subprocesses to be complete
wait
cleanup

